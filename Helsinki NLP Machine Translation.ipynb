{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBJ3UUrRtrOY",
        "outputId": "9b19222f-21d9-4128-9f91-29f818a8e818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mrgtgg5Munw6",
        "outputId": "6b437def-8039-42df-9475-ba81f7584c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Veri seti sütunları: ['Sentence']\n"
          ]
        }
      ],
      "source": [
        "print(\"Veri seti sütunları:\", df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zN_ND6b2xQ4"
      },
      "source": [
        "İNGİLİZCEDEN TÜRKÇEYE ÇEVİRİ KISMI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR6u7tFEtuKF",
        "outputId": "e7dd26ed-b2f1-423a-a446-e4bbd153bcce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Başarıyla tamamlandı! Çevrilmiş veri 'cevirilmis_veri.csv' dosyasına kaydedildi.\n"
          ]
        }
      ],
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import pandas as pd\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Giriş yap (tokenınızı girin)\n",
        "login(token=\"your_token\")\n",
        "\n",
        "# Model ve tokenizer'ı yükle\n",
        "model_name = 'Helsinki-NLP/opus-mt-tc-big-en-tr'\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Çeviri fonksiyonu\n",
        "def translate_to_turkish(text):\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model.generate(inputs, max_length=512)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Veri setini yükle\n",
        "df = pd.read_csv('test_dataset_500_sentences.csv')\n",
        "\n",
        "# Çevirileri yap\n",
        "df['turkce_ceviri'] = df['Sentence'].apply(translate_to_turkish)\n",
        "\n",
        "# Sonuçları kaydet\n",
        "df.to_csv('cevirilmis_veri.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(\"Başarıyla tamamlandı! Çevrilmiş veri 'cevirilmis_veri.csv' dosyasına kaydedildi.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7RR2YOT26XB"
      },
      "source": [
        "Model yükleme süresi: Modelin diske yüklenme süresi\n",
        "\n",
        "Toplam çeviri süresi: Tüm cümlelerin çevrilmesi için geçen süre\n",
        "\n",
        "Cümle başına ortalama süre: Her bir cümle için ortalama işlem süresi\n",
        "\n",
        "En hızlı/en yavaş çeviri: En kısa ve en uzun süren çeviriler\n",
        "\n",
        "Throughput: Saniyede çevrilebilen cümle sayısı"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O3svEOx0H9c",
        "outputId": "941ea221-c8da-4b14-f752-72676a66ed99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model yükleniyor: Helsinki-NLP/opus-mt-tc-big-en-tr...\n",
            "Model yükleme süresi: 7.11 saniye\n",
            "\n",
            "Toplam 500 cümle çevirisi başlatılıyor...\n",
            "Warm-up yapılıyor...\n",
            "Çeviriler başlıyor...\n",
            "50/500 cümle çevrildi. Son cümle süresi: 1.5113 s\n",
            "100/500 cümle çevrildi. Son cümle süresi: 1.3831 s\n",
            "150/500 cümle çevrildi. Son cümle süresi: 1.5894 s\n",
            "200/500 cümle çevrildi. Son cümle süresi: 1.6674 s\n",
            "250/500 cümle çevrildi. Son cümle süresi: 1.4410 s\n",
            "300/500 cümle çevrildi. Son cümle süresi: 1.6324 s\n",
            "350/500 cümle çevrildi. Son cümle süresi: 1.5042 s\n",
            "400/500 cümle çevrildi. Son cümle süresi: 1.1340 s\n",
            "450/500 cümle çevrildi. Son cümle süresi: 1.5423 s\n",
            "500/500 cümle çevrildi. Son cümle süresi: 1.5276 s\n",
            "\n",
            "=== Performans Raporu ===\n",
            "Toplam çeviri süresi: 809.66 saniye\n",
            "Toplam cümle sayısı: 500\n",
            "Ortalama cümle çeviri süresi: 1.6193 saniye\n",
            "En hızlı çeviri: 0.7883 saniye\n",
            "En yavaş çeviri: 2.3837 saniye\n",
            "Saniyede çevrilen cümle: 0.62 (cümle/saniye)\n",
            "\n",
            "Sonuçlar 'translated_sentences_with_timing.csv' dosyasına kaydedildi.\n",
            "\n",
            "Örnek çeviriler:\n",
            "\n",
            "1. Orijinal: The quick brown fox jumps over the lazy dog.\n",
            "   Çeviri: Hızlı kahverengi tilki tembel köpeğin üzerinden atlar.\n",
            "\n",
            "2. Orijinal: Artificial intelligence is changing the world.\n",
            "   Çeviri: Yapay zeka dünyayı değiştiriyor.\n",
            "\n",
            "3. Orijinal: Machine learning is a subset of artificial intelligence.\n",
            "   Çeviri: Makine öğrenimi yapay zekanın bir alt kümesidir.\n"
          ]
        }
      ],
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import pandas as pd\n",
        "import time\n",
        "from huggingface_hub import login\n",
        "import warnings\n",
        "\n",
        "# Uyarıları gizle\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Giriş yap\n",
        "login(token=\"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\")\n",
        "\n",
        "# Model ve tokenizer'ı yükle\n",
        "model_name = 'Helsinki-NLP/opus-mt-tc-big-en-tr'\n",
        "print(f\"Model yükleniyor: {model_name}...\")\n",
        "start_load = time.time()\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "load_time = time.time() - start_load\n",
        "print(f\"Model yükleme süresi: {load_time:.2f} saniye\")\n",
        "\n",
        "# Çeviri fonksiyonu\n",
        "def translate_to_turkish(text):\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    outputs = model.generate(inputs, max_length=512)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Veri setini yükle\n",
        "df = pd.read_csv('test_dataset_500_sentences.csv')\n",
        "\n",
        "# Performans ölçümü\n",
        "total_sentences = len(df)\n",
        "print(f\"\\nToplam {total_sentences} cümle çevirisi başlatılıyor...\")\n",
        "\n",
        "total_time = 0\n",
        "individual_times = []\n",
        "\n",
        "# Örnek çeviri ile warm-up\n",
        "print(\"Warm-up yapılıyor...\")\n",
        "translate_to_turkish(\"This is a warm-up sentence.\")\n",
        "\n",
        "# Gerçek çeviriler\n",
        "print(\"Çeviriler başlıyor...\")\n",
        "start_total = time.time()\n",
        "\n",
        "for i, sentence in enumerate(df['Sentence'], 1):\n",
        "    start = time.time()\n",
        "    translation = translate_to_turkish(sentence)\n",
        "    elapsed = time.time() - start\n",
        "    individual_times.append(elapsed)\n",
        "\n",
        "    df.at[i-1, 'Turkish_Translation'] = translation\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print(f\"{i}/{total_sentences} cümle çevrildi. Son cümle süresi: {elapsed:.4f} s\")\n",
        "\n",
        "total_time = time.time() - start_total\n",
        "\n",
        "# İstatistikleri hesapla\n",
        "avg_time = total_time / total_sentences\n",
        "min_time = min(individual_times)\n",
        "max_time = max(individual_times)\n",
        "\n",
        "# Sonuçları kaydet\n",
        "output_filename = 'translated_sentences_with_timing.csv'\n",
        "df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "# Performans raporu\n",
        "print(\"\\n=== Performans Raporu ===\")\n",
        "print(f\"Toplam çeviri süresi: {total_time:.2f} saniye\")\n",
        "print(f\"Toplam cümle sayısı: {total_sentences}\")\n",
        "print(f\"Ortalama cümle çeviri süresi: {avg_time:.4f} saniye\")\n",
        "print(f\"En hızlı çeviri: {min_time:.4f} saniye\")\n",
        "print(f\"En yavaş çeviri: {max_time:.4f} saniye\")\n",
        "print(f\"Saniyede çevrilen cümle: {1/avg_time:.2f} (cümle/saniye)\")\n",
        "print(f\"\\nSonuçlar '{output_filename}' dosyasına kaydedildi.\")\n",
        "\n",
        "# İlk 3 çeviriyi göster\n",
        "print(\"\\nÖrnek çeviriler:\")\n",
        "for i, (orig, trans) in enumerate(zip(df['Sentence'].head(3), df['Turkish_Translation'].head(3)), 1):\n",
        "    print(f\"\\n{i}. Orijinal: {orig}\\n   Çeviri: {trans}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWDyZO0o3dVy"
      },
      "source": [
        "GPU VRAM kullanımını nvidia-smi veya benzeri araçlarla kaydet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oRRw5QH3krb",
        "outputId": "731ddc53-9c50-42ec-8e16-52c886146131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU izleme başlatılıyor...\n",
            "Model yükleniyor...\n",
            "Model yükleme süresi: 7.56s | GPU'ya aktarıldı\n",
            "\n",
            "Toplam 500 cümle çevirisi başlatılıyor...\n",
            "50/500 | Son cümle: 0.115s\n",
            "100/500 | Son cümle: 0.168s\n",
            "150/500 | Son cümle: 0.112s\n",
            "200/500 | Son cümle: 0.106s\n",
            "250/500 | Son cümle: 0.141s\n",
            "300/500 | Son cümle: 0.114s\n",
            "350/500 | Son cümle: 0.136s\n",
            "400/500 | Son cümle: 0.081s\n",
            "450/500 | Son cümle: 0.128s\n",
            "500/500 | Son cümle: 0.115s\n",
            "\n",
            "Toplam çeviri süresi: 63.58s\n",
            "Ortalama süre/cümle: 0.127s\n",
            "GPU izleme durduruldu\n",
            "Çeviriler kaydedildi\n",
            "\n",
            "Maksimum VRAM Kullanımı: 1070 MB\n",
            "Ortalama GPU Utilizasyonu: 35.71111111111111%\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "import csv\n",
        "import threading\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import pandas as pd\n",
        "from huggingface_hub import login\n",
        "\n",
        "# GPU VRAM izleme fonksiyonu\n",
        "def monitor_gpu(output_file, interval=1, stop_event=None):\n",
        "    with open(output_file, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['timestamp', 'gpu_utilization', 'memory_used', 'memory_total'])\n",
        "\n",
        "        while not stop_event.is_set():\n",
        "            try:\n",
        "                result = subprocess.check_output([\n",
        "                    'nvidia-smi',\n",
        "                    '--query-gpu=utilization.gpu,memory.used,memory.total',\n",
        "                    '--format=csv,noheader,nounits'\n",
        "                ]).decode('utf-8').strip()\n",
        "\n",
        "                util, used, total = result.split(',')\n",
        "                writer.writerow([time.time(), util, used, total])\n",
        "            except Exception as e:\n",
        "                print(f\"Monitoring error: {str(e)}\")\n",
        "            time.sleep(interval)\n",
        "\n",
        "# GPU log dosyasını ayarla\n",
        "gpu_log_file = 'gpu_usage.csv'\n",
        "stop_event = threading.Event()\n",
        "monitor_thread = threading.Thread(\n",
        "    target=monitor_gpu,\n",
        "    args=(gpu_log_file, 0.5, stop_event)\n",
        ")\n",
        "\n",
        "# Model yükleme\n",
        "login(token=\"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\")\n",
        "model_name = 'Helsinki-NLP/opus-mt-tc-big-en-tr'\n",
        "\n",
        "print(\"GPU izleme başlatılıyor...\")\n",
        "monitor_thread.start()\n",
        "\n",
        "try:\n",
        "    # Modeli GPU'ya yükle\n",
        "    print(\"Model yükleniyor...\")\n",
        "    start_load = time.time()\n",
        "    model = MarianMTModel.from_pretrained(model_name).to('cuda')\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    load_time = time.time() - start_load\n",
        "    print(f\"Model yükleme süresi: {load_time:.2f}s | GPU'ya aktarıldı\")\n",
        "\n",
        "    # Çeviri fonksiyonu\n",
        "    def translate_to_turkish(text):\n",
        "        inputs = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, padding=True).to('cuda')\n",
        "        outputs = model.generate(inputs, max_length=512)\n",
        "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Veri setini yükle\n",
        "    df = pd.read_csv('test_dataset_500_sentences.csv')\n",
        "    total_sentences = len(df)\n",
        "    print(f\"\\nToplam {total_sentences} cümle çevirisi başlatılıyor...\")\n",
        "\n",
        "    # Performans ölçümü\n",
        "    start_total = time.time()\n",
        "    for i, sentence in enumerate(df['Sentence'], 1):\n",
        "        start = time.time()\n",
        "        df.at[i-1, 'Turkish_Translation'] = translate_to_turkish(sentence)\n",
        "        elapsed = time.time() - start\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"{i}/{total_sentences} | Son cümle: {elapsed:.3f}s\")\n",
        "\n",
        "    total_time = time.time() - start_total\n",
        "    print(f\"\\nToplam çeviri süresi: {total_time:.2f}s\")\n",
        "    print(f\"Ortalama süre/cümle: {total_time/total_sentences:.3f}s\")\n",
        "\n",
        "finally:\n",
        "    # Kaynakları temizle\n",
        "    stop_event.set()\n",
        "    monitor_thread.join()\n",
        "    print(\"GPU izleme durduruldu\")\n",
        "\n",
        "    # Sonuçları kaydet\n",
        "    df.to_csv('translated_sentences_final.csv', index=False, encoding='utf-8-sig')\n",
        "    print(\"Çeviriler kaydedildi\")\n",
        "\n",
        "    # GPU kullanım analizi\n",
        "    try:\n",
        "        gpu_data = pd.read_csv(gpu_log_file)\n",
        "        peak_mem = gpu_data['memory_used'].max()\n",
        "        avg_util = gpu_data['gpu_utilization'].mean()\n",
        "        print(f\"\\nMaksimum VRAM Kullanımı: {peak_mem} MB\")\n",
        "        print(f\"Ortalama GPU Utilizasyonu: {avg_util}%\")\n",
        "    except Exception as e:\n",
        "        print(f\"GPU log analiz hatası: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnePrx074Q6N",
        "outputId": "3df5639a-8b3b-4328-90d4-7243ff8118e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hugging Face Hub'dan dosya bilgileri alınıyor...\n",
            "\n",
            "=== Model Dosya Listesi ===\n",
            ".gitattributes\n",
            "README.md\n",
            "benchmark_results.txt\n",
            "benchmark_translations.zip\n",
            "config.json\n",
            "generation_config.json\n",
            "pytorch_model.bin\n",
            "source.spm\n",
            "special_tokens_map.json\n",
            "target.spm\n",
            "tf_model.h5\n",
            "tokenizer_config.json\n",
            "vocab.json\n",
            "\n",
            "=== Detaylı Dosya Boyutları ===\n",
            ".gitattributes: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "README.md: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "benchmark_results.txt: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "benchmark_translations.zip: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "config.json: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "generation_config.json: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "pytorch_model.bin: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "source.spm: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "special_tokens_map.json: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "target.spm: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "tf_model.h5: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "tokenizer_config.json: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "vocab.json: Boyut bilgisi alınamadı ('HfApi' object has no attribute 'get_path_info')\n",
            "\n",
            "Toplam Boyut: 0.00 MB\n",
            "\n",
            "=== Lokal Cache'teki Model Dosyaları ===\n",
            "\n",
            "Model dosyalarının lokal yolu: /root/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-tc-big-en-tr\n",
            "blobs/33b04f8d169e8e7458ebd8fbdc5d2c6e2e454f9071f42f935b6b0c1263fe30c2: 447.96 MB\n",
            "blobs/cd0c475692178b6c626aadaef01bd8f98d8053946938e4e67005fc1e4811d797: 0.79 MB\n",
            "blobs/180d3f94ddfee5585d78b702290ded0f4f9bd40f299349c8383b32a579fefad4: 0.76 MB\n",
            "blobs/e2229e55db12a9a5284018e443f1f4afed4efe43: 0.00 MB\n",
            "blobs/a14b7b52e29c8d81e023e664924cb9ed0832896e: 0.00 MB\n",
            "blobs/9649c310ccaa09a66c7a93acf6f61dfdfa8e2ebc: 0.00 MB\n",
            "blobs/0dc21962e176abd434d8e6eeb05a971259bbf8b2: 1.43 MB\n",
            "blobs/6dc4d430ddbd24171268d73da061ce9f0b092911: 0.00 MB\n",
            "blobs/7bc7e1973431752bcbb083c090c3c8f1e6eb3389d2e2e0faf9bf1a85d969a789: 448.02 MB\n",
            "refs/main: 0.00 MB\n",
            "refs/refs/pr/10: 0.00 MB\n",
            ".no_exist/e539fc16a8a1a0ea5950eb339b595bfcce990e90/tokenizer.json: 0.00 MB\n",
            ".no_exist/e539fc16a8a1a0ea5950eb339b595bfcce990e90/model.safetensors.index.json: 0.00 MB\n",
            ".no_exist/e539fc16a8a1a0ea5950eb339b595bfcce990e90/model.safetensors: 0.00 MB\n",
            ".no_exist/e539fc16a8a1a0ea5950eb339b595bfcce990e90/adapter_config.json: 0.00 MB\n",
            ".no_exist/e539fc16a8a1a0ea5950eb339b595bfcce990e90/chat_template.jinja: 0.00 MB\n",
            ".no_exist/e539fc16a8a1a0ea5950eb339b595bfcce990e90/added_tokens.json: 0.00 MB\n",
            ".no_exist/e539fc16a8a1a0ea5950eb339b595bfcce990e90/target_vocab.json: 0.00 MB\n",
            "snapshots/e539fc16a8a1a0ea5950eb339b595bfcce990e90/vocab.json: 1.43 MB\n",
            "snapshots/e539fc16a8a1a0ea5950eb339b595bfcce990e90/special_tokens_map.json: 0.00 MB\n",
            "snapshots/e539fc16a8a1a0ea5950eb339b595bfcce990e90/config.json: 0.00 MB\n",
            "snapshots/e539fc16a8a1a0ea5950eb339b595bfcce990e90/source.spm: 0.76 MB\n",
            "snapshots/e539fc16a8a1a0ea5950eb339b595bfcce990e90/tokenizer_config.json: 0.00 MB\n",
            "snapshots/e539fc16a8a1a0ea5950eb339b595bfcce990e90/target.spm: 0.79 MB\n",
            "snapshots/e539fc16a8a1a0ea5950eb339b595bfcce990e90/generation_config.json: 0.00 MB\n",
            "snapshots/e539fc16a8a1a0ea5950eb339b595bfcce990e90/pytorch_model.bin: 448.02 MB\n",
            "snapshots/a6e22c148f5f9af9d3fff02f1c3ec1e89f7032d2/model.safetensors: 447.96 MB\n",
            "\n",
            "Lokal Toplam Boyut: 1797.93 MB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from huggingface_hub import HfApi\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Model bilgileri\n",
        "model_name = 'Helsinki-NLP/opus-mt-tc-big-en-tr'\n",
        "\n",
        "# 1. Yöntem: Hugging Face API ile dosya boyutlarını alma\n",
        "print(\"Hugging Face Hub'dan dosya bilgileri alınıyor...\")\n",
        "api = HfApi()\n",
        "files = api.list_repo_files(model_name, repo_type=\"model\")\n",
        "\n",
        "print(\"\\n=== Model Dosya Listesi ===\")\n",
        "for file in files:\n",
        "    print(file)\n",
        "\n",
        "# 2. Yöntem: Detaylı boyut bilgileri için\n",
        "print(\"\\n=== Detaylı Dosya Boyutları ===\")\n",
        "total_size = 0\n",
        "for file in files:\n",
        "    try:\n",
        "        file_info = api.get_path_info(f\"{model_name}/{file}\")\n",
        "        size_mb = file_info.size / (1024 * 1024)\n",
        "        print(f\"{file}: {size_mb:.2f} MB\")\n",
        "        total_size += file_info.size\n",
        "    except Exception as e:\n",
        "        print(f\"{file}: Boyut bilgisi alınamadı ({str(e)})\")\n",
        "\n",
        "print(f\"\\nToplam Boyut: {total_size/(1024*1024):.2f} MB\")\n",
        "\n",
        "# 3. Yöntem: Lokal cache'teki dosyaları analiz etme\n",
        "print(\"\\n=== Lokal Cache'teki Model Dosyaları ===\")\n",
        "try:\n",
        "    # Model ve tokenizer'ı yükle (cache'e indirilsin)\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Cache dizinini bul\n",
        "    from transformers import TRANSFORMERS_CACHE\n",
        "    cache_dir = os.path.join(TRANSFORMERS_CACHE, f\"models--{model_name.replace('/', '--')}\")\n",
        "\n",
        "    if not os.path.exists(cache_dir):\n",
        "        cache_dir = model.config.name_or_path\n",
        "\n",
        "    print(f\"\\nModel dosyalarının lokal yolu: {cache_dir}\")\n",
        "\n",
        "    # Dosya boyutlarını hesapla\n",
        "    total_local = 0\n",
        "    for root, dirs, files in os.walk(cache_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
        "            print(f\"{os.path.relpath(file_path, cache_dir)}: {size_mb:.2f} MB\")\n",
        "            total_local += os.path.getsize(file_path)\n",
        "\n",
        "    print(f\"\\nLokal Toplam Boyut: {total_local/(1024*1024):.2f} MB\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nHata oluştu: {str(e)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
